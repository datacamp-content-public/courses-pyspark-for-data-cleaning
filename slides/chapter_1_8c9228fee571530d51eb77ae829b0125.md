---
title: Insert title here
key: 8c9228fee571530d51eb77ae829b0125

---
## Identifying Outliers in PySpark

```yaml
type: "TitleSlide"
key: "be0107f3da"
```

`@lower_third`

name: Aiden Vincent Johnson
title: Data Scientist | Innovator | Mentor


`@script`
Welcome to this course on Identifying Outliers in Pyspark. Identifying Outliers is a necessary step in any data science project. In this course, you'll learn how to apply a common method to identify outliers in your data using PySpark.


---
## What are Outliers?

```yaml
type: "FullSlide"
key: "662fd7ac14"
```

`@part1`
- Outliers are extreme values that fall far outside the mean and standard deviation of a set of observations.
- Outliers can mislead the training process in building machine learning models.
- Outliers may be real anomalies in the observations or artificial errors.
![](https://assets.datacamp.com/production/repositories/4360/datasets/4de2e3ca5ffa48ca1b2f931e7867ca462701dd76/outputpoly-1.png)


`@script`



---
## Identify Outliers based on Extreme Value Analysis

```yaml
type: "TwoColumns"
key: "e86037980b"
```

`@part1`
- Assumes a normal distribution
- Expected values fall within 1.5 times 1st & 3rd quartile
- Find observations outside the 1.5 * IQR
- Flag outliers for removal
- Review outliers
- Delete outliers from data


`@part2`
![](https://assets.datacamp.com/production/repositories/4360/datasets/09a5b441a0d3158dc1cbe8cfb35f1dc67b480a32/Screen%20Shot%202019-01-01%20at%207.50.41%20PM.png)


`@script`



---
## Review The Boxplot

```yaml
type: "TwoColumns"
key: "16157102c7"
```

`@part1`
Pieces of boxplot


`@part2`
Labeled Boxplot of Environment column


`@script`



---
## Define IQR

```yaml
type: "FullCodeSlide"
key: "60b64d9e31"
```

`@part1`
```python
nomin = ['Rank', 'Well Being', 'Work', 'Environment']
quantiles = [0.25, 0.75]

cut_off_points = []
for name in nomin:
    quants = imputed.approxQuantile(name, quantiles, 0.05)

    IQR = quants[1] - quants[0]
    cut_off_points.append((name, [
        quants[0] - 1.5 * IQR,
        quants[1] + 1.5 * IQR,
    ]))

cut_off_points = dict(cut_off_points)```


`@script`



---
## Flag points outside IQR

```yaml
type: "FullCodeSlide"
key: "45e2b238aa"
```

`@part1`
```python
outliers = imputed.select(*['id'] + [
       (
           (df[f] < cut_off_points[f][0]) |
           (df[f] > cut_off_points[f][1])
       ).alias(f + '_o') for f in nomin
  ])```


`@script`



---
## Review Outliers

```yaml
type: "FullCodeSlide"
key: "090eef0d93"
```

`@part1`
```python
## join df with outlier flags

with_outliers_flag = df.join(outliers, on='Id')

(
    with_outliers_flag
    .filter('Environment_o')
    .select('Id', 'Well Being', 'Work', 'Environment)
    .show()
)```


`@script`
* Update code to reflect new data set
* show table of output data - may need split slide


---
## Filter data with outliers flags

```yaml
type: "FullCodeSlide"
key: "46e2d5d9fa"
```

`@part1`
```python
## Final Data Frame with Outliers removed
no_outliers = (
    with_outliers_flag
    .filter('!Environment_o')
    .select(df.columns)
)```


`@script`



---
## Final Slide

```yaml
type: "FinalSlide"
key: "651eaf9d46"
```

`@script`


